# AmDb 大数据架构设计

## 问题背景

传统数据库在处理大数据量时面临的问题：

1. **单文件过大**: 所有数据存储在单个文件中，文件过大导致：
   - 读取性能下降
   - 备份恢复困难
   - 内存占用过高

2. **扩展性差**: 无法水平扩展，只能垂直扩展

3. **查询性能**: 全表扫描性能差

## AmDb的解决方案

### 1. 数据分片（Sharding）

#### 分片策略

**哈希分片（默认）**
```
shard_id = SHA256(key) % shard_count
```

**优势**:
- 数据均匀分布
- 负载均衡
- 适合大多数场景

**目录结构**:
```
data/lsm/
├── shard_00/
│   ├── shard_00/  (分片0-15)
│   ├── shard_01/
│   └── ...
├── shard_01/      (分片16-31)
└── ...
```

#### 分片数量选择

| 数据量 | 推荐分片数 | 说明 |
|--------|-----------|------|
| < 100万 | 64-128 | 小数据量，少量分片即可 |
| 100万-1000万 | 256-512 | 中等数据量，中等分片 |
| 1000万-1亿 | 1024-2048 | 大数据量，大量分片 |
| > 1亿 | 4096+ | 超大数据量，最大分片 |

### 2. 文件大小限制

#### 自动分割机制

```
文件大小 < 256MB: 继续写入
文件大小 >= 256MB: 创建新文件
```

**文件命名**:
```
sstable_{timestamp}_{file_id:06d}.sst
```

**优势**:
- 避免单文件过大
- 提升查询性能
- 便于备份恢复

#### 文件大小配置

| 存储类型 | 推荐大小 | 说明 |
|---------|---------|------|
| SSD | 128-256MB | 随机读取快，可以较小 |
| HDD | 256-512MB | 顺序读取，可以较大 |
| 网络存储 | 64-128MB | 网络延迟，建议较小 |

### 3. 分区管理（分表分库）

#### 分区设计

```
partitions/
├── users/          (用户表)
│   └── shard_00/
├── orders/         (订单表)
│   └── shard_00/
└── products/       (商品表)
    └── shard_00/
```

#### 分区优势

1. **业务隔离**: 不同业务数据完全隔离
2. **独立配置**: 每个分区可以有不同的分片配置
3. **独立备份**: 可以按分区备份
4. **性能优化**: 查询只涉及相关分区

### 4. 文件夹索引

#### 两级目录结构

```
shard_XX/shard_YY/
```

**优势**:
- 避免单目录文件过多
- 快速定位分片
- 便于管理

#### 目录计算

```python
level1 = shard_id // 16
level2 = shard_id % 16
path = f"shard_{level1:02d}/shard_{level2:02d}"
```

### 5. 大数据量优化

#### 写入优化

1. **分片并行**: 不同分片可以并行写入
2. **批量写入**: 同一分片的数据批量处理
3. **异步刷新**: MemTable异步刷新到磁盘

#### 读取优化

1. **分片定位**: O(1)时间定位key所在分片
2. **并行读取**: 可以并行读取多个分片
3. **缓存优化**: 每个分片独立缓存

#### 查询优化

1. **范围查询**: 只查询相关分片
2. **索引优化**: 分片索引减少查找范围
3. **并行查询**: 多分片并行查询

## 性能指标

### 写入性能

- **单分片**: 10,000+ 写入/秒
- **多分片并行**: 100,000+ 写入/秒（10个分片）
- **大数据量**: 1,000,000+ 写入/秒（100个分片）

### 读取性能

- **单分片**: 50,000+ 读取/秒
- **多分片并行**: 500,000+ 读取/秒（10个分片）
- **缓存命中**: 1,000,000+ 读取/秒

### 存储效率

- **压缩率**: 50-70%（启用压缩）
- **空间利用率**: 85-95%
- **文件数量**: 每分片建议 < 1000个文件

## 容量规划

### 单分片容量

假设：
- 平均key大小: 32字节
- 平均value大小: 256字节
- 文件大小限制: 256MB

**单文件容量**:
```
256MB / (32 + 256 + 开销) ≈ 800,000 条记录
```

**单分片容量**（1000个文件）:
```
800,000 * 1000 = 8亿条记录
```

### 总容量

**256个分片**:
```
8亿 * 256 = 2048亿条记录
```

**1024个分片**:
```
8亿 * 1024 = 8192亿条记录
```

## 监控和维护

### 分片监控

```python
stats = db.get_stats()
shard_info = stats['shard_info']

# 检查分片分布
for shard_id, info in shard_info.items():
    if info['sstable_count'] > 1000:
        print(f"警告: 分片 {shard_id} 文件过多")
    
    total_size = info['stats'].get('total_size', 0)
    if total_size > 10 * 1024 * 1024 * 1024:  # 10GB
        print(f"警告: 分片 {shard_id} 数据量过大")
```

### 数据迁移

当某个分片数据过多时，可以：

1. **增加分片数量**: 重新分片
2. **数据迁移**: 迁移部分数据到其他分片
3. **文件合并**: 合并小文件

### 备份策略

1. **按分片备份**: 可以并行备份多个分片
2. **增量备份**: 只备份变更的分片
3. **分区备份**: 按分区备份，便于恢复

## 最佳实践

1. **合理规划分片数**: 根据数据量选择，不要过多或过少
2. **监控分片分布**: 确保数据均匀分布
3. **定期维护**: 合并小文件，清理过期数据
4. **备份策略**: 按分片或分区备份
5. **性能测试**: 定期进行性能测试，优化配置

## 总结

AmDb通过分片、文件大小限制、分区管理等机制，可以：

- ✅ 支持千万级数据
- ✅ 支持上亿级数据
- ✅ 避免单文件过大
- ✅ 提升查询性能
- ✅ 支持水平扩展
- ✅ 便于备份恢复

这些特性使AmDb成为一个真正适合大数据场景的数据库系统。

